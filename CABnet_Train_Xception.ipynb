{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540f4c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in c:\\users\\aokra\\anaconda3\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\aokra\\anaconda3\\lib\\site-packages (from keras_applications) (1.18.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\aokra\\anaconda3\\lib\\site-packages (from keras_applications) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\aokra\\anaconda3\\lib\\site-packages (from h5py->keras_applications) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425a8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7038ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Global_attention_block(inputs):\n",
    "    shape=K.int_shape(inputs)\n",
    "    \n",
    "    x=tf.keras.layers.AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
    "    x=Conv2D(shape[3],1, padding='same') (x)\n",
    "    x=Activation('relu') (x)\n",
    "\n",
    "    x=Conv2D(shape[3],1, padding='same') (x)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    C_A=tf.keras.layers.Multiply()([x,inputs])\n",
    "    \n",
    "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True)) (C_A)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    S_A=tf.keras.layers.Multiply()([x,C_A])\n",
    "    return S_A\n",
    "\n",
    "def Category_attention_block(inputs,classes,k):\n",
    "    shape=K.int_shape(inputs)\n",
    "    F=Conv2D(k*classes,1, padding='same') (inputs)\n",
    "    F=tf.keras.layers.BatchNormalization() (F)\n",
    "    F1=Activation('relu') (F)\n",
    "    \n",
    "    F2=F1\n",
    "    x=tf.keras.layers.GlobalMaxPool2D()(F2)\n",
    "    \n",
    "    x=tf.keras.layers.Reshape((classes,k)) (x)\n",
    "    S=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))  (x)\n",
    "    \n",
    "    x=tf.keras.layers.Reshape((shape[1],shape[2],classes,k)) (F1)\n",
    "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))  (x)\n",
    "    x=tf.keras.layers.Multiply()([S,x])\n",
    "    M=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (x)\n",
    "    \n",
    "    semantic=tf.keras.layers.Multiply()([inputs,M])\n",
    "    return semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ba3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+'.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58f65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756f3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    #C:\\Users\\aokra\\Dataset\\Messidor\\Messidor_DR__Binary_Classification\\train\n",
    "    dataParam={'messidor': [960,240,2,'Dataset/Messidor/Messidor_DR__Binary_Classification/train',\n",
    "                            'Dataset/Messidor/Messidor_DR__Binary_Classification/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"xception_cab_messidor_weights.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 16)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b23bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.3553 - acc: 0.5156\n",
      "Epoch 00001: acc improved from -inf to 0.51562, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 202s 3s/step - loss: 2.3553 - acc: 0.5156\n",
      "Epoch 1/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6641 - acc: 0.6135 \n",
      "Epoch 00001: acc improved from 0.51562 to 0.61354, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1030s 17s/step - loss: 0.6641 - acc: 0.6135\n",
      "Epoch 2/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6250 - acc: 0.6948 \n",
      "Epoch 00002: acc improved from 0.61354 to 0.69479, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1037s 17s/step - loss: 0.6250 - acc: 0.6948\n",
      "Epoch 3/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5862 - acc: 0.7292 \n",
      "Epoch 00003: acc improved from 0.69479 to 0.72917, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1129s 19s/step - loss: 0.5862 - acc: 0.7292\n",
      "Epoch 4/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5716 - acc: 0.7302 \n",
      "Epoch 00004: acc improved from 0.72917 to 0.73021, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1131s 19s/step - loss: 0.5716 - acc: 0.7302\n",
      "Epoch 5/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5515 - acc: 0.7521 \n",
      "Epoch 00005: acc improved from 0.73021 to 0.75208, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 948s 16s/step - loss: 0.5515 - acc: 0.7521\n",
      "Epoch 6/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5217 - acc: 0.7812 \n",
      "Epoch 00006: acc improved from 0.75208 to 0.78125, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1005s 17s/step - loss: 0.5217 - acc: 0.7812\n",
      "Epoch 7/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4977 - acc: 0.7937 \n",
      "Epoch 00007: acc improved from 0.78125 to 0.79375, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 977s 16s/step - loss: 0.4977 - acc: 0.7937\n",
      "Epoch 8/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5271 - acc: 0.8042 \n",
      "Epoch 00008: acc improved from 0.79375 to 0.80417, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1140s 19s/step - loss: 0.5271 - acc: 0.8042\n",
      "Epoch 9/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4513 - acc: 0.8219 \n",
      "Epoch 00009: acc improved from 0.80417 to 0.82187, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1039s 17s/step - loss: 0.4513 - acc: 0.8219\n",
      "Epoch 10/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4755 - acc: 0.7927 \n",
      "Epoch 00010: acc did not improve from 0.82187\n",
      "60/60 [==============================] - 928s 15s/step - loss: 0.4755 - acc: 0.7927\n",
      "Epoch 11/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4466 - acc: 0.8302 \n",
      "Epoch 00011: acc improved from 0.82187 to 0.83021, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 934s 16s/step - loss: 0.4466 - acc: 0.8302\n",
      "Epoch 12/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3511 - acc: 0.8542 \n",
      "Epoch 00012: acc improved from 0.83021 to 0.85417, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 933s 16s/step - loss: 0.3511 - acc: 0.8542\n",
      "Epoch 13/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3369 - acc: 0.8531 \n",
      "Epoch 00013: acc did not improve from 0.85417\n",
      "60/60 [==============================] - 917s 15s/step - loss: 0.3369 - acc: 0.8531\n",
      "Epoch 14/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3636 - acc: 0.8510 \n",
      "Epoch 00014: acc did not improve from 0.85417\n",
      "60/60 [==============================] - 921s 15s/step - loss: 0.3636 - acc: 0.8510\n",
      "Epoch 15/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2934 - acc: 0.8729 \n",
      "Epoch 00015: acc improved from 0.85417 to 0.87292, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 924s 15s/step - loss: 0.2934 - acc: 0.8729\n",
      "Epoch 16/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2916 - acc: 0.8823 \n",
      "Epoch 00016: acc improved from 0.87292 to 0.88229, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 917s 15s/step - loss: 0.2916 - acc: 0.8823\n",
      "Epoch 17/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2912 - acc: 0.8792 \n",
      "Epoch 00017: acc did not improve from 0.88229\n",
      "60/60 [==============================] - 915s 15s/step - loss: 0.2912 - acc: 0.8792\n",
      "Epoch 18/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3018 - acc: 0.8854 \n",
      "Epoch 00018: acc improved from 0.88229 to 0.88542, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 922s 15s/step - loss: 0.3018 - acc: 0.8854\n",
      "Epoch 19/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2411 - acc: 0.9073 \n",
      "Epoch 00019: acc improved from 0.88542 to 0.90729, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 924s 15s/step - loss: 0.2411 - acc: 0.9073\n",
      "Epoch 20/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2627 - acc: 0.9010 \n",
      "Epoch 00020: acc did not improve from 0.90729\n",
      "60/60 [==============================] - 952s 16s/step - loss: 0.2627 - acc: 0.9010\n",
      "Epoch 21/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2360 - acc: 0.9052 \n",
      "Epoch 00021: acc did not improve from 0.90729\n",
      "60/60 [==============================] - 956s 16s/step - loss: 0.2360 - acc: 0.9052\n",
      "Epoch 22/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2015 - acc: 0.9094 \n",
      "Epoch 00022: acc improved from 0.90729 to 0.90938, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 957s 16s/step - loss: 0.2015 - acc: 0.9094\n",
      "Epoch 23/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2469 - acc: 0.8969 \n",
      "Epoch 00023: acc did not improve from 0.90938\n",
      "60/60 [==============================] - 973s 16s/step - loss: 0.2469 - acc: 0.8969\n",
      "Epoch 24/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2307 - acc: 0.9219 \n",
      "Epoch 00024: acc improved from 0.90938 to 0.92188, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 966s 16s/step - loss: 0.2307 - acc: 0.9219\n",
      "Epoch 25/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1761 - acc: 0.9354 \n",
      "Epoch 00025: acc improved from 0.92188 to 0.93542, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 959s 16s/step - loss: 0.1761 - acc: 0.9354\n",
      "Epoch 26/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1887 - acc: 0.9312 \n",
      "Epoch 00026: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 961s 16s/step - loss: 0.1887 - acc: 0.9312\n",
      "Epoch 27/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1573 - acc: 0.9333 \n",
      "Epoch 00027: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 968s 16s/step - loss: 0.1573 - acc: 0.9333\n",
      "Epoch 28/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2006 - acc: 0.9271 \n",
      "Epoch 00028: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 1008s 17s/step - loss: 0.2006 - acc: 0.9271\n",
      "Epoch 29/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1366 - acc: 0.9458 \n",
      "Epoch 00029: acc improved from 0.93542 to 0.94583, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1014s 17s/step - loss: 0.1366 - acc: 0.9458\n",
      "Epoch 30/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1590 - acc: 0.9427 \n",
      "Epoch 00030: acc did not improve from 0.94583\n",
      "60/60 [==============================] - 996s 17s/step - loss: 0.1590 - acc: 0.9427\n",
      "Epoch 31/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1623 - acc: 0.9406 \n",
      "Epoch 00031: acc did not improve from 0.94583\n",
      "60/60 [==============================] - 981s 16s/step - loss: 0.1623 - acc: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1412 - acc: 0.9469 \n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 00032: acc improved from 0.94583 to 0.94687, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 958s 16s/step - loss: 0.1412 - acc: 0.9469\n",
      "Epoch 33/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1258 - acc: 0.9490 \n",
      "Epoch 00033: acc improved from 0.94687 to 0.94896, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 960s 16s/step - loss: 0.1258 - acc: 0.9490\n",
      "Epoch 34/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1205 - acc: 0.9604 \n",
      "Epoch 00034: acc improved from 0.94896 to 0.96042, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 962s 16s/step - loss: 0.1205 - acc: 0.9604\n",
      "Epoch 35/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1050 - acc: 0.9656 \n",
      "Epoch 00035: acc improved from 0.96042 to 0.96562, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 958s 16s/step - loss: 0.1050 - acc: 0.9656\n",
      "Epoch 36/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.9760 \n",
      "Epoch 00036: acc improved from 0.96562 to 0.97604, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 957s 16s/step - loss: 0.0744 - acc: 0.9760\n",
      "Epoch 37/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0944 - acc: 0.9604 \n",
      "Epoch 00037: acc did not improve from 0.97604\n",
      "60/60 [==============================] - 955s 16s/step - loss: 0.0944 - acc: 0.9604\n",
      "Epoch 38/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0708 - acc: 0.9719 \n",
      "Epoch 00038: acc did not improve from 0.97604\n",
      "60/60 [==============================] - 967s 16s/step - loss: 0.0708 - acc: 0.9719\n",
      "Epoch 39/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0737 - acc: 0.9740 \n",
      "Epoch 00039: acc did not improve from 0.97604\n",
      "60/60 [==============================] - 954s 16s/step - loss: 0.0737 - acc: 0.9740\n",
      "Epoch 40/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0718 - acc: 0.9760 \n",
      "Epoch 00040: acc did not improve from 0.97604\n",
      "60/60 [==============================] - 951s 16s/step - loss: 0.0718 - acc: 0.9760\n",
      "Epoch 41/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0871 - acc: 0.9688 \n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.97604\n",
      "60/60 [==============================] - 956s 16s/step - loss: 0.0871 - acc: 0.9688\n",
      "Epoch 42/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0548 - acc: 0.9833 \n",
      "Epoch 00042: acc improved from 0.97604 to 0.98333, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 956s 16s/step - loss: 0.0548 - acc: 0.9833\n",
      "Epoch 43/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0894 - acc: 0.9729 \n",
      "Epoch 00043: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 952s 16s/step - loss: 0.0894 - acc: 0.9729\n",
      "Epoch 44/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0435 - acc: 0.9833 \n",
      "Epoch 00044: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 1011s 17s/step - loss: 0.0435 - acc: 0.9833\n",
      "Epoch 45/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0509 - acc: 0.9823 \n",
      "Epoch 00045: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 1026s 17s/step - loss: 0.0509 - acc: 0.9823\n",
      "Epoch 46/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.9812 \n",
      "Epoch 00046: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 1033s 17s/step - loss: 0.0486 - acc: 0.9812\n",
      "Epoch 47/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0339 - acc: 0.9865 \n",
      "Epoch 00047: acc improved from 0.98333 to 0.98646, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 974s 16s/step - loss: 0.0339 - acc: 0.9865\n",
      "Epoch 48/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1108 - acc: 0.9688 \n",
      "Epoch 00048: acc did not improve from 0.98646\n",
      "60/60 [==============================] - 982s 16s/step - loss: 0.1108 - acc: 0.9688\n",
      "Epoch 49/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0364 - acc: 0.9885 \n",
      "Epoch 00049: acc improved from 0.98646 to 0.98854, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 956s 16s/step - loss: 0.0364 - acc: 0.9885\n",
      "Epoch 50/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0559 - acc: 0.9792 \n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 00050: acc did not improve from 0.98854\n",
      "60/60 [==============================] - 962s 16s/step - loss: 0.0559 - acc: 0.9792\n",
      "Epoch 51/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0454 - acc: 0.9823 \n",
      "Epoch 00051: acc did not improve from 0.98854\n",
      "60/60 [==============================] - 1023s 17s/step - loss: 0.0454 - acc: 0.9823\n",
      "Epoch 52/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0400 - acc: 0.9844 \n",
      "Epoch 00052: acc did not improve from 0.98854\n",
      "60/60 [==============================] - 1028s 17s/step - loss: 0.0400 - acc: 0.9844\n",
      "Epoch 53/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.9792 \n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 00053: acc did not improve from 0.98854\n",
      "60/60 [==============================] - 1039s 17s/step - loss: 0.0433 - acc: 0.9792\n",
      "Epoch 54/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0244 - acc: 0.9917 \n",
      "Epoch 00054: acc improved from 0.98854 to 0.99167, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1042s 17s/step - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 55/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0358 - acc: 0.9885 \n",
      "Epoch 00055: acc did not improve from 0.99167\n",
      "60/60 [==============================] - 1042s 17s/step - loss: 0.0358 - acc: 0.9885\n",
      "Epoch 56/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0166 - acc: 0.9979 \n",
      "Epoch 00056: acc improved from 0.99167 to 0.99792, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 1034s 17s/step - loss: 0.0166 - acc: 0.9979\n",
      "Epoch 57/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0131 - acc: 0.9948 \n",
      "Epoch 00057: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 970s 16s/step - loss: 0.0131 - acc: 0.9948\n",
      "Epoch 58/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0217 - acc: 0.9896 \n",
      "Epoch 00058: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 948s 16s/step - loss: 0.0217 - acc: 0.9896\n",
      "Epoch 59/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0167 - acc: 0.9958 \n",
      "Epoch 00059: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 950s 16s/step - loss: 0.0167 - acc: 0.9958\n",
      "Epoch 60/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0229 - acc: 0.9917 \n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 00060: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 940s 16s/step - loss: 0.0229 - acc: 0.9917\n",
      "Epoch 61/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0207 - acc: 0.9885 \n",
      "Epoch 00061: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 940s 16s/step - loss: 0.0207 - acc: 0.9885\n",
      "Epoch 62/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0177 - acc: 0.9937 \n",
      "Epoch 00062: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 940s 16s/step - loss: 0.0177 - acc: 0.9937\n",
      "Epoch 63/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9937 \n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 00063: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 942s 16s/step - loss: 0.0178 - acc: 0.9937\n",
      "Epoch 64/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.0207 - acc: 0.9948 \n",
      "Epoch 00064: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 941s 16s/step - loss: 0.0207 - acc: 0.9948\n",
      "Epoch 65/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9958 \n",
      "Epoch 00065: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 941s 16s/step - loss: 0.0138 - acc: 0.9958\n",
      "Epoch 66/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0136 - acc: 0.9958 \n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 00066: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 943s 16s/step - loss: 0.0136 - acc: 0.9958\n",
      "Epoch 67/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0189 - acc: 0.9906 \n",
      "Epoch 00067: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 938s 16s/step - loss: 0.0189 - acc: 0.9906\n",
      "Epoch 68/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9969 \n",
      "Epoch 00068: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 939s 16s/step - loss: 0.0086 - acc: 0.9969\n",
      "Epoch 69/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0089 - acc: 0.9990 \n",
      "Epoch 00069: acc improved from 0.99792 to 0.99896, saving model to xception_cab_messidor_weights.hdf5\n",
      "60/60 [==============================] - 947s 16s/step - loss: 0.0089 - acc: 0.9990\n",
      "Epoch 70/70\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.9969 \n",
      "Epoch 00070: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 947s 16s/step - loss: 0.0106 - acc: 0.9969\n",
      "15/15 [==============================] - 39s 3s/step - loss: 0.7900 - acc: 0.8167\n",
      "Test loss: 0.789995014667511\n",
      "Test accuracy: 0.8166666626930237\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"    \n",
    "loss_fun= 'categorical_crossentropy'  \n",
    "gpu_num=1\n",
    "k=4\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=224\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('xception',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "x=Global_attention_block(base_out)\n",
    "base_out=Category_attention_block(x,classes,k)\n",
    "\n",
    "shape=K.int_shape(base_out)  \n",
    "x=GlobalAveragePooling2D()(base_out)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "    \n",
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'xception',\n",
    "                                     lr1,lr2,1,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a8aa36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'xception')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d85b3666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[9.97606516e-01 2.39349972e-03]\n",
      " [1.09377988e-01 8.90622079e-01]\n",
      " [9.99972224e-01 2.77190902e-05]\n",
      " [9.99997377e-01 2.57727243e-06]\n",
      " [9.99997139e-01 2.88033607e-06]\n",
      " [3.17807309e-02 9.68219221e-01]\n",
      " [3.10282886e-01 6.89717054e-01]\n",
      " [9.99691486e-01 3.08576884e-04]\n",
      " [9.48043346e-01 5.19566238e-02]\n",
      " [9.99996066e-01 3.87774526e-06]\n",
      " [9.78772283e-01 2.12276876e-02]\n",
      " [9.99979138e-01 2.09032478e-05]\n",
      " [7.25623686e-04 9.99274433e-01]\n",
      " [9.99818146e-01 1.81902404e-04]\n",
      " [2.97636569e-01 7.02363431e-01]\n",
      " [5.99895045e-03 9.94000971e-01]\n",
      " [2.21890421e-03 9.97781098e-01]\n",
      " [9.28935111e-01 7.10649565e-02]\n",
      " [9.98393476e-01 1.60646893e-03]\n",
      " [3.02488238e-01 6.97511792e-01]\n",
      " [9.99995708e-01 4.29697684e-06]\n",
      " [9.99972939e-01 2.71161462e-05]\n",
      " [9.99942183e-01 5.78223335e-05]\n",
      " [2.23022792e-03 9.97769833e-01]\n",
      " [7.76679367e-02 9.22332048e-01]\n",
      " [9.31949794e-01 6.80501387e-02]\n",
      " [9.99993801e-01 6.21320942e-06]\n",
      " [9.99998808e-01 1.13430485e-06]\n",
      " [9.99816716e-01 1.83294207e-04]\n",
      " [9.55488920e-01 4.45110314e-02]\n",
      " [5.21357395e-02 9.47864234e-01]\n",
      " [9.60098987e-06 9.99990344e-01]\n",
      " [9.99407530e-01 5.92527853e-04]\n",
      " [9.99085784e-01 9.14255623e-04]\n",
      " [9.99602497e-01 3.97509546e-04]\n",
      " [5.47465384e-01 4.52534646e-01]\n",
      " [9.98683274e-01 1.31670828e-03]\n",
      " [8.23166013e-01 1.76833987e-01]\n",
      " [9.99998093e-01 1.90322669e-06]\n",
      " [9.99961734e-01 3.82509206e-05]\n",
      " [9.99996066e-01 3.98679913e-06]\n",
      " [9.99981761e-01 1.82432104e-05]\n",
      " [9.99999285e-01 7.47104934e-07]\n",
      " [9.99796331e-01 2.03706091e-04]\n",
      " [4.12168168e-03 9.95878339e-01]\n",
      " [9.34056580e-01 6.59434050e-02]\n",
      " [9.99924898e-01 7.50813415e-05]\n",
      " [7.02439845e-01 2.97560215e-01]\n",
      " [9.99193609e-01 8.06367898e-04]\n",
      " [1.17620258e-02 9.88238037e-01]\n",
      " [9.95028913e-01 4.97112004e-03]\n",
      " [9.99981046e-01 1.89657276e-05]\n",
      " [3.12464505e-01 6.87535465e-01]\n",
      " [9.99091983e-01 9.08036251e-04]\n",
      " [9.99967217e-01 3.27753551e-05]\n",
      " [9.99995112e-01 4.88362457e-06]\n",
      " [3.58144462e-05 9.99964237e-01]\n",
      " [9.99996901e-01 3.05104959e-06]\n",
      " [9.99888301e-01 1.11744688e-04]\n",
      " [9.49137844e-03 9.90508676e-01]\n",
      " [9.99999762e-01 2.61772868e-07]\n",
      " [9.99828935e-01 1.71038890e-04]\n",
      " [9.98469770e-01 1.53022853e-03]\n",
      " [9.99962687e-01 3.73288276e-05]\n",
      " [4.69709575e-01 5.30290365e-01]\n",
      " [9.99886155e-01 1.13777933e-04]\n",
      " [9.88077164e-01 1.19228167e-02]\n",
      " [9.99407291e-01 5.92706318e-04]\n",
      " [9.99759257e-01 2.40704598e-04]\n",
      " [9.99946475e-01 5.35502295e-05]\n",
      " [9.99997497e-01 2.55511986e-06]\n",
      " [3.26265721e-03 9.96737301e-01]\n",
      " [2.03642800e-01 7.96357214e-01]\n",
      " [9.75262702e-01 2.47372836e-02]\n",
      " [9.99828696e-01 1.71278123e-04]\n",
      " [7.78833628e-01 2.21166447e-01]\n",
      " [1.25199673e-04 9.99874830e-01]\n",
      " [9.98608768e-01 1.39124610e-03]\n",
      " [6.69526935e-01 3.30473065e-01]\n",
      " [2.04664655e-02 9.79533553e-01]\n",
      " [8.85311782e-01 1.14688180e-01]\n",
      " [9.99820888e-01 1.79167138e-04]\n",
      " [9.99990225e-01 9.78671142e-06]\n",
      " [5.83907306e-01 4.16092694e-01]\n",
      " [9.99999404e-01 5.86134945e-07]\n",
      " [9.99946713e-01 5.32451049e-05]\n",
      " [9.70003664e-01 2.99963560e-02]\n",
      " [9.99978542e-01 2.14386091e-05]\n",
      " [9.99998569e-01 1.37447353e-06]\n",
      " [9.99612033e-01 3.87966604e-04]\n",
      " [8.25141147e-02 9.17485833e-01]\n",
      " [9.99779522e-01 2.20436661e-04]\n",
      " [9.99988198e-01 1.17797445e-05]\n",
      " [9.50623512e-01 4.93764766e-02]\n",
      " [9.99233484e-01 7.66532379e-04]\n",
      " [9.95496511e-01 4.50352067e-03]\n",
      " [4.57454780e-06 9.99995470e-01]\n",
      " [9.99337256e-01 6.62664534e-04]\n",
      " [2.43986072e-03 9.97560143e-01]\n",
      " [8.37131665e-06 9.99991655e-01]\n",
      " [9.92511218e-07 9.99999046e-01]\n",
      " [1.51464506e-03 9.98485386e-01]\n",
      " [3.44551052e-04 9.99655485e-01]\n",
      " [1.34277812e-04 9.99865651e-01]\n",
      " [2.72895932e-01 7.27104008e-01]\n",
      " [2.25650379e-03 9.97743487e-01]\n",
      " [3.26474992e-06 9.99996781e-01]\n",
      " [3.61402548e-04 9.99638557e-01]\n",
      " [1.65708536e-06 9.99998331e-01]\n",
      " [8.88106064e-04 9.99111831e-01]\n",
      " [1.94003751e-05 9.99980569e-01]\n",
      " [4.74050830e-05 9.99952555e-01]\n",
      " [9.17169273e-01 8.28307420e-02]\n",
      " [9.93450403e-01 6.54956652e-03]\n",
      " [5.66019978e-08 1.00000000e+00]\n",
      " [3.55667376e-04 9.99644279e-01]\n",
      " [2.11252162e-04 9.99788821e-01]\n",
      " [1.01452737e-04 9.99898553e-01]\n",
      " [7.78236699e-06 9.99992251e-01]\n",
      " [1.45551216e-09 1.00000000e+00]\n",
      " [5.72940160e-04 9.99427080e-01]\n",
      " [9.32254016e-01 6.77460209e-02]\n",
      " [2.28797439e-02 9.77120280e-01]\n",
      " [1.07817054e-04 9.99892116e-01]\n",
      " [2.21709549e-01 7.78290510e-01]\n",
      " [9.82047617e-02 9.01795268e-01]\n",
      " [1.53164045e-04 9.99846816e-01]\n",
      " [4.07273881e-04 9.99592721e-01]\n",
      " [9.85938241e-05 9.99901414e-01]\n",
      " [4.12713848e-02 9.58728611e-01]\n",
      " [5.19454363e-04 9.99480546e-01]\n",
      " [1.82650270e-04 9.99817431e-01]\n",
      " [1.46050984e-02 9.85394955e-01]\n",
      " [8.38020525e-04 9.99161959e-01]\n",
      " [2.38429144e-04 9.99761522e-01]\n",
      " [1.07554933e-02 9.89244461e-01]\n",
      " [6.69820249e-01 3.30179691e-01]\n",
      " [1.17387790e-05 9.99988317e-01]\n",
      " [3.62207029e-05 9.99963760e-01]\n",
      " [6.03259195e-06 9.99993920e-01]\n",
      " [5.93992649e-03 9.94060099e-01]\n",
      " [1.32977206e-03 9.98670220e-01]\n",
      " [7.79023045e-04 9.99220967e-01]\n",
      " [7.52007836e-05 9.99924779e-01]\n",
      " [6.22469187e-01 3.77530783e-01]\n",
      " [2.68225539e-02 9.73177493e-01]\n",
      " [3.48932925e-04 9.99651074e-01]\n",
      " [9.69056427e-01 3.09435483e-02]\n",
      " [8.51521236e-06 9.99991536e-01]\n",
      " [2.09650211e-03 9.97903466e-01]\n",
      " [7.61810690e-04 9.99238253e-01]\n",
      " [1.43628486e-03 9.98563707e-01]\n",
      " [8.26508222e-06 9.99991775e-01]\n",
      " [3.26746762e-01 6.73253298e-01]\n",
      " [9.99654651e-01 3.45328241e-04]\n",
      " [1.44753176e-05 9.99985576e-01]\n",
      " [8.25488951e-06 9.99991775e-01]\n",
      " [1.69780586e-04 9.99830246e-01]\n",
      " [9.93690133e-01 6.30980032e-03]\n",
      " [1.02158980e-02 9.89784062e-01]\n",
      " [2.15688925e-02 9.78431046e-01]\n",
      " [2.19964935e-03 9.97800291e-01]\n",
      " [2.18680521e-04 9.99781311e-01]\n",
      " [5.31903356e-02 9.46809709e-01]\n",
      " [6.32158875e-01 3.67841065e-01]\n",
      " [5.49942207e-08 1.00000000e+00]\n",
      " [2.70926230e-05 9.99972939e-01]\n",
      " [2.15282617e-03 9.97847199e-01]\n",
      " [1.14544621e-03 9.98854518e-01]\n",
      " [5.65522758e-04 9.99434412e-01]\n",
      " [6.21557534e-01 3.78442407e-01]\n",
      " [8.24723486e-07 9.99999166e-01]\n",
      " [3.26323062e-01 6.73676908e-01]\n",
      " [6.44849334e-03 9.93551493e-01]\n",
      " [5.68800278e-05 9.99943137e-01]\n",
      " [8.94553785e-04 9.99105394e-01]\n",
      " [5.55803890e-05 9.99944448e-01]\n",
      " [2.56005410e-06 9.99997497e-01]\n",
      " [5.50187519e-03 9.94498193e-01]\n",
      " [2.25682603e-03 9.97743249e-01]\n",
      " [2.34833150e-03 9.97651637e-01]\n",
      " [6.82621476e-06 9.99993205e-01]\n",
      " [9.88330483e-01 1.16695920e-02]\n",
      " [3.88986096e-02 9.61101353e-01]\n",
      " [1.50796948e-02 9.84920323e-01]\n",
      " [1.21380086e-04 9.99878645e-01]\n",
      " [9.99140978e-01 8.58994259e-04]\n",
      " [6.14231112e-06 9.99993801e-01]\n",
      " [1.60745294e-05 9.99983907e-01]\n",
      " [1.71277483e-04 9.99828696e-01]\n",
      " [2.92370842e-05 9.99970794e-01]\n",
      " [9.46691318e-04 9.99053299e-01]\n",
      " [2.46445246e-08 1.00000000e+00]\n",
      " [3.42920225e-06 9.99996543e-01]\n",
      " [4.07812791e-03 9.95921850e-01]\n",
      " [2.17357408e-02 9.78264213e-01]\n",
      " [9.36772525e-01 6.32274821e-02]\n",
      " [8.70495060e-05 9.99912977e-01]\n",
      " [1.30437501e-03 9.98695672e-01]\n",
      " [2.83148466e-03 9.97168481e-01]\n",
      " [5.18719077e-08 1.00000000e+00]\n",
      " [2.44370056e-03 9.97556329e-01]\n",
      " [3.03149037e-03 9.96968567e-01]\n",
      " [7.22484440e-02 9.27751541e-01]\n",
      " [1.37408087e-02 9.86259222e-01]\n",
      " [1.87485566e-04 9.99812543e-01]\n",
      " [9.75989223e-01 2.40107160e-02]\n",
      " [9.84117796e-05 9.99901533e-01]\n",
      " [7.70161867e-01 2.29838073e-01]\n",
      " [9.69509408e-03 9.90304828e-01]\n",
      " [1.42383724e-02 9.85761642e-01]\n",
      " [1.04073189e-01 8.95926774e-01]\n",
      " [9.88541365e-01 1.14586549e-02]\n",
      " [5.75821923e-06 9.99994278e-01]\n",
      " [2.75870366e-06 9.99997258e-01]\n",
      " [2.24503968e-03 9.97754991e-01]\n",
      " [3.68195444e-01 6.31804526e-01]\n",
      " [6.19442342e-03 9.93805647e-01]\n",
      " [1.87738601e-03 9.98122633e-01]\n",
      " [5.09885194e-06 9.99994874e-01]\n",
      " [2.95661718e-01 7.04338253e-01]\n",
      " [5.57836502e-05 9.99944210e-01]\n",
      " [1.88683363e-04 9.99811351e-01]\n",
      " [1.05846124e-02 9.89415407e-01]\n",
      " [9.56690019e-06 9.99990463e-01]\n",
      " [1.45408874e-02 9.85459089e-01]\n",
      " [1.98213047e-06 9.99997973e-01]\n",
      " [2.81020824e-04 9.99718964e-01]\n",
      " [1.56015827e-04 9.99843955e-01]\n",
      " [1.17639764e-04 9.99882340e-01]\n",
      " [2.06679797e-05 9.99979377e-01]\n",
      " [4.97377245e-04 9.99502659e-01]\n",
      " [3.49782058e-04 9.99650240e-01]\n",
      " [5.49535453e-01 4.50464576e-01]\n",
      " [1.37629495e-05 9.99986291e-01]\n",
      " [9.57778931e-01 4.22211289e-02]\n",
      " [2.27571139e-03 9.97724235e-01]\n",
      " [9.94414210e-01 5.58574591e-03]\n",
      " [2.27204891e-05 9.99977231e-01]\n",
      " [5.06521959e-04 9.99493480e-01]]\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73  24]\n",
      " [ 20 123]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.78      0.75      0.77        97\n",
      "    referable       0.84      0.86      0.85       143\n",
      "\n",
      "     accuracy                           0.82       240\n",
      "    macro avg       0.81      0.81      0.81       240\n",
      " weighted avg       0.82      0.82      0.82       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490cf231",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-318fc5c47ad5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Truth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989bf3ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-166337b1ff0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplot_metric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBinaryClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Visualisation with plot_metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_probas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'non-referable'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'referable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Figures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfa1ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "def GradCam(model, img_array, layer_name, eps=1e-8):\n",
    "    '''\n",
    "    Creates a grad-cam heatmap given a model and a layer name contained with that model\n",
    "    \n",
    "\n",
    "    Args:\n",
    "      model: tf model\n",
    "      img_array: (img_width x img_width) numpy array\n",
    "      layer_name: str\n",
    "\n",
    "\n",
    "    Returns \n",
    "      uint8 numpy array with shape (img_height, img_width)\n",
    "\n",
    "    '''\n",
    "\n",
    "    gradModel = Model(\n",
    "\t\t\tinputs=[model.inputs],\n",
    "\t\t\toutputs=[model.get_layer(layer_name).output,\n",
    "\t\t\t\tmodel.output])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "\t\t\t# cast the image tensor to a float-32 data type, pass the\n",
    "\t\t\t# image through the gradient model, and grab the loss\n",
    "\t\t\t# associated with the specific class index\n",
    "      inputs = tf.cast(img_array, tf.float32)\n",
    "      (convOutputs, predictions) = gradModel(inputs)\n",
    "      loss = predictions[:, 0]\n",
    "\t\t# use automatic differentiation to compute the gradients\n",
    "    grads = tape.gradient(loss, convOutputs)\n",
    "    \n",
    "    # compute the guided gradients\n",
    "    castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "    castGrads = tf.cast(grads > 0, \"float32\")\n",
    "    guidedGrads = castConvOutputs * castGrads * grads\n",
    "\t\t# the convolution and guided gradients have a batch dimension\n",
    "\t\t# (which we don't need) so let's grab the volume itself and\n",
    "\t\t# discard the batch\n",
    "    convOutputs = convOutputs[0]\n",
    "    guidedGrads = guidedGrads[0]\n",
    "    # compute the average of the gradient values, and using them\n",
    "\t\t# as weights, compute the ponderation of the filters with\n",
    "\t\t# respect to the weights\n",
    "    weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "  \n",
    "    # grab the spatial dimensions of the input image and resize\n",
    "\t\t# the output class activation map to match the input image\n",
    "\t\t# dimensions\n",
    "    (w, h) = (img_array.shape[2], img_array.shape[1])\n",
    "    heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "\t\t# normalize the heatmap such that all values lie in the range\n",
    "\t\t# [0, 1], scale the resulting values to the range [0, 255],\n",
    "\t\t# and then convert to an unsigned 8-bit integer\n",
    "    numer = heatmap - np.min(heatmap)\n",
    "    denom = (heatmap.max() - heatmap.min()) + eps\n",
    "    heatmap = numer / denom\n",
    "    # heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "\t\t# return the resulting heatmap to the calling function\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def sigmoid(x, a, b, c):\n",
    "    return c / (1 + np.exp(-a * (x-b)))\n",
    "\n",
    "def superimpose(img_bgr, cam, thresh, emphasize=False):\n",
    "    \n",
    "    '''\n",
    "    Superimposes a grad-cam heatmap onto an image for model interpretation and visualization.\n",
    "    \n",
    "\n",
    "    Args:\n",
    "      image: (img_width x img_height x 3) numpy array\n",
    "      grad-cam heatmap: (img_width x img_width) numpy array\n",
    "      threshold: float\n",
    "      emphasize: boolean\n",
    "\n",
    "    Returns \n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "\n",
    "    '''\n",
    "    heatmap = cv2.resize(cam, (img_bgr.shape[1], img_bgr.shape[0]))\n",
    "    if emphasize:\n",
    "        heatmap = sigmoid(heatmap, 50, thresh, 1)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    hif = .8\n",
    "    superimposed_img = heatmap * hif + img_bgr\n",
    "    superimposed_img = np.minimum(superimposed_img, 255.0).astype(np.uint8)  # scale 0 to 255  \n",
    "    superimposed_img_rgb = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return superimposed_img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b1cb0fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-8d77337fa0ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Read RGB image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dataset/Messidor/Messidor_DR__Binary_Classification/test/non_referable/20051214_51953_0100_PP.tig'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Maintain output window utill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "  \n",
    "# Save image in set directory\n",
    "# Read RGB image\n",
    "img = cv2.imread('Dataset/Messidor/Messidor_DR__Binary_Classification/test/non_referable/20051214_51953_0100_PP.tig') \n",
    "\n",
    "layer_name = 'Conv_1'\n",
    "grad_cam=GradCam(model,np.expand_dims(img, axis=0),out)\n",
    "grad_cam_superimposed = superimpose(img, grad_cam, 0.5, emphasize=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.imshow(grad_cam_superimposed)\n",
    "plt.axis('off')\n",
    "plt.title('Conv_1 Grad-CAM heat-map')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29583c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
